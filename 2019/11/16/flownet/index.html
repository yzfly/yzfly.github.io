<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="FlowNet"><meta name="keywords" content="deeplearning Optical-Flow"><meta name="author" content="yz-liu"><meta name="copyright" content="yz-liu"><title>FlowNet | yzliu的小窝</title><link rel="shortcut icon" href="/imgs/AI.ico"><link rel="stylesheet" href="/css/index.css?version=1.7.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.7.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><link rel="dns-prefetch" href="http://ta.qq.com"><script>(function() {
   var hm = document.createElement("script");
   hm.src = "https://tajs.qq.com/stats?sId=66525319";
   var s = document.getElementsByTagName("script")[0];
   s.parentNode.insertBefore(hm, s);
 })();</script><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
} </script><meta name="generator" content="Hexo 4.2.0"></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#flownet"><span class="toc-number">1.</span> <span class="toc-text"> FlowNet</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#论文阅读"><span class="toc-number">1.1.</span> <span class="toc-text"> 论文阅读</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#abstract"><span class="toc-number">1.1.1.</span> <span class="toc-text"> Abstract</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#introduction"><span class="toc-number">1.1.2.</span> <span class="toc-text"> Introduction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#related-work"><span class="toc-number">1.1.3.</span> <span class="toc-text"> Related Work</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#network-architectures"><span class="toc-number">1.1.4.</span> <span class="toc-text"> Network Architectures</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#training-data"><span class="toc-number">1.1.5.</span> <span class="toc-text"> Training Data</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#existing-datasets"><span class="toc-number">1.1.5.1.</span> <span class="toc-text"> Existing Datasets</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#flying-chairs"><span class="toc-number">1.1.5.2.</span> <span class="toc-text"> Flying Chairs</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#data-augmentation"><span class="toc-number">1.1.5.3.</span> <span class="toc-text"> Data Augmentation</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#experiments"><span class="toc-number">1.1.6.</span> <span class="toc-text"> Experiments</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#network-and-trainging-details"><span class="toc-number">1.1.6.1.</span> <span class="toc-text"> Network and Trainging Details</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#results"><span class="toc-number">1.1.6.2.</span> <span class="toc-text"> Results</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#analysis"><span class="toc-number">1.1.6.3.</span> <span class="toc-text"> Analysis</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#conclusion"><span class="toc-number">1.1.7.</span> <span class="toc-text"> Conclusion</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#阅读心得"><span class="toc-number">1.2.</span> <span class="toc-text"> 阅读心得</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#疑问"><span class="toc-number">1.3.</span> <span class="toc-text"> 疑问</span></a></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/imgs/avatar.jpeg"></div><div class="author-info__name text-center">yz-liu</div><div class="author-info__description text-center"></div><div class="follow-button"><a href="https://github.com/yzfly" target="_blank" rel="noopener">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">2</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">2</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">2</span></a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://cdn.nlark.com/yuque/0/2020/png/211857/1583144212593-c7c016a1-24c0-47cc-bac7-4252aa4fb2f4.png)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">yzliu的小窝</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a><a class="site-page" href="/slides">Slides</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> 搜索</span></a></span></div><div id="post-info"><div id="post-title">FlowNet</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-11-16</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/deeplearning/">deeplearning</a><div class="post-meta-wordcount"><span>字数总计: </span><span class="word-count">8k</span><span class="post-meta__separator">|</span><span>阅读时长: 24 分钟</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h1 id="flownet"><a class="markdownIt-Anchor" href="#flownet"></a> FlowNet</h1>
<p>原论文：</p>
<p><a href="https://arxiv.org/abs/1504.06852" target="_blank" rel="noopener">FlowNet: Learning Optical Flow with Convolutional Networks</a></p>
<h2 id="论文阅读"><a class="markdownIt-Anchor" href="#论文阅读"></a> 论文阅读</h2>
<p>​	FlowNet 系列有1.0 和 2.0 版本，本次阅读的是最初版本的 FlowNet。其首先采用神经网络对光流进行预测。</p>
<h3 id="abstract"><a class="markdownIt-Anchor" href="#abstract"></a> Abstract</h3>
<p>​	CNNs(卷积神经网络) 最近在一系列计算机视觉任务中都取得了巨大的成功，特别是在与识别相关的任务上。然而CNN在光流估计领域却并不成功。在这篇论文中，我们设计了一个合适的网络，能够将光流估计问题作为监督学习任务来处理。我们提出并比较了两种网络架构：一种是通用架构（FlowNetS），另一种网络架构 (FlowNetC) 则包含了 Correlation 层，用于将不同图像位置的特征向量关联到一起。</p>
<h3 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h3>
<p>​	卷积神经网络已经成为了计算机视觉领域诸多任务的可选方法。它们经典的应用是在图片分类领域，但是最近的神经网络结构也能够用于像素级的预测，如语义分割和从单张图片中获取深度图。在本文中，我们打算训练端到端的神经网络来从一对图片中预测光流场。</p>
<p>​	光流估计需要精确的逐像素的定位，同时也需要找出两张输入图片之间的联系。**这不仅需要学习图片的特征表示，同时也需要学习如何在两幅图像的不同位置将其匹配。**在这个方面，光流估计与之前的 CNNs 应用有着本质的区别。</p>
<p>​	因为不清楚该任务是否能够使用标准的 CNN 网络结构来完成，我们另外开发了一个具有明确提供匹配功能的相关层的架构。该结构使用端到端的方法训练。其思想是充分利用神经网络的能力来学习到多个尺度和抽象层次上的强特征，并帮助网络基于这些特征找到实际的对应关系。在关联层（correlation layer）之上（或者说之后）的网络层将从这些匹配中学习如何预测光流。令人惊讶的是，使用这种方法来帮助网络学习是不必要的，并且即使是原始网络都能够学会以很好的精确度来预测光流。</p>
<p>​	训练这样一个预测光流的网络需要一个充分的足够大的训练集。虽然数据增强技术的确有效，但现有的光流数据集还是太小，不足以训练出与当前最先进水平相当的网络。众所周知，为现有的真实视频材料获取光流地面真值是很难的。为了获取足够数量的数据，我们选择牺牲图片的真实性（Trading in realism for quantity）。我们生成了一个合成的飞椅数据集，它由来自 Flickr 的随机背景图像组成，我们在上面覆盖了椅子分段图像，这些椅子来自 cvpr2014 的论文 《Seeing 3D chairs: exemplar part-based 2D-3D alignment using a large dataset of CAD models》。飞椅数据集中的数据与现实世界几乎没有共同点，但是我们可以生成自定义属性的任意数量的样例。令人惊讶的是，即使不进行微调，在这些数据上训练得到的 CNN 模型也能够很好的泛化到现实世界的数据集中。</p>
<p>​	<strong>借助于高效的 GPU 实现 CNN，我们的方法快于任何竞争对手。我们的网络即使是在全分辨率的 Sintel dataset 预测光流，也能够达到每秒 10 张图片的速度，在所有实时的算法中取得了当前最佳结果。</strong></p>
<h3 id="related-work"><a class="markdownIt-Anchor" href="#related-work"></a> Related Work</h3>
<p><strong>光流</strong> 自 Horn 和 Schunck 的工作后，<strong>变分方法一直主导着光流估计领域。<strong>后续引入了许多改进方法。最近的研究重点是大位移，并且</strong>组合匹配方法</strong>也已经集成到变分方法之中。称为 DeepMatching 和 DeepFlow 的方法与我们使用稀疏卷积和最大池化将有限元信息从细到粗地聚合起来的工作有关。然而， 它并没有进行任何学习，并且各个参数是人为确定的。后续的称为 EpicFlow 的工作更加强调稀疏匹配的质量，因为DeepMatching 和 DeepFlow 方法得到的匹配只是在尊重图像边界的条件下对稠密光流场的插值。 我们只使用变分方法对卷积神经网络预测的光流进行可选的优化，不需要任何手工设计的方法进行聚类、匹配和插值。</p>
<p>​	在之前已经有许多学者将机器学习的技巧应用到光流估计之中。Sun 等学者研究了光流的统计特性并使用高斯尺度混合学习了正则化器。Rosenbaum等学者使用高斯混合模型模拟光流的局部统计特性。Black 等人计算了流场训练集的主成分。为了估计光流，他们之后估计了这些 “基流”的线性组合的系数。其它的方法训练分类器从许多不同的惯性估计中选择或者获得遮挡概率。</p>
<p>​	现今已经有人构建神经网络使用无监督学习方法来学习视频帧之间的视差或者运动信息。这些模型通常使用多重交互作用来模拟一对图片之间的关系。然后可以从潜在变量中推断得出视差和光流。Taylor 等人使用分解门控受限的玻尔兹曼机来处理该任务。Konda和 Memisevic 使用一种特殊的称为“synchrony autoencoder” 的自编码器。虽然在受控的设置下这些方法效果良好并且能够从视频中学习到对活动识别有用的信息，但在现实视频中，他们无法与经典方法相媲美。</p>
<h3 id="network-architectures"><a class="markdownIt-Anchor" href="#network-architectures"></a> Network Architectures</h3>
<p><strong>卷积神经网络</strong> 使用反向传播算法训练的神经网络在大规模图片分类任务上被 Krizhevsky 证明是十分有效的。这导致了将 CNN 应用到各种计算机视觉任务上的工作激增。</p>
<p>​	虽然当前并没有使用 CNNs 来估计光流的工作，但已经有了与神经网络相匹配的研究。Fisher 等人使用经过监督或非监督学习的CNNs 来提取特征表示，并使用欧氏距离来匹配这些特征。Zbontar 和 LeCun 使用孪生网络训练CNN 来预测图像局部区域的相似性。<strong>我们方法与这些方法的一个巨大区别是：这些方法是基于图像局部区域的并且将空间聚合操作留给后处理，本文的网络直接预测完整的光流。</strong></p>
<p>​	CNNs 最近的应用包括语义分割、深度预测、关键点预测和边缘检测。这些任务与光流估计的共同之处是他们都涉及<strong>像素级别预测</strong>。由于我们的网络受到这些逐像素预测任务进步的很大启发，因此我们简要的回顾这些不同的方法。</p>
<p>​	最简单的方法是使用“滑动窗口”的方式来应用卷积神经网络，为每个输入的图像局部区域计算预测输出。该方法在许多任务上效果良好，但也存在缺点：高额的计算成本（即使使用了复用特征图的优化实现）并且每个图像局部的天然缺陷导致无法输出全局属性，如锐边。另一种简单的方法是上采样特征图至理想的全分辨率并且将其叠加到一起，得到连接像素级的特征向量用于预测感兴趣的数据。</p>
<p>​	Eigen 等学者<strong>通过同时输入粗糙的预测值和图片来训练一个额外的网络用于细化粗糙的深度图。<strong>Long 和 Dosovitskiy 等学者迭代的</strong>使用 ’上采样卷积‘ 层来细化粗特征图</strong>。我们的方法整合了上述两项工作的想法。与 Long 等学者不同的是，我们不只是上卷了粗预测结果，同时也上卷了整个粗糙特征图，使得能够将更多的高层信息转化为精细的预测。与 Dosovitskiy 等学者不同，我们将 “上采样卷积”结果与收缩网络的特征拼接在一起使用。</p>
<p>​	众所周知，在拥有足够的标签数据条件下，卷积神经网络十分擅于学习到输入与输出之间的关系。因此我们使用端到端的学习方法来预测光流：使用包含图像对和光流真实值的数据集，我们训练一个神经网络来直接从图片中预测得到 x-y 光流。但什么样的网络架构才能更好的达成目标呢？</p>
<p>​	**一种简单的方法是将输入的图像对叠加到一起，将其直接输入到一个通用的网络中，使网络自行决定如何处理图像对来提取其中的运动信息。**该网络如图 2 所示。我们将只包含卷积层的网络架构称为“FlowNetSimple”.</p>
<p>​	理论上来说，网络足够大的情况下，该网络能够预测光流。然而，我们无法确定局部梯度优化方法如随机梯度下降算法能够使得网络最终收敛到我们想要的状态（局部最优解）。因此，在给定数据和优化技术的情况下，使用手工设计的不那么通用的网络可能会更加有效。</p>
<p>​	**一种直接的方法是为两张图片设计两条独立但等价的处理流，并在之后的处理流程中将其结合到一起，如图 2 所示。在这种架构下，网络被限制为首先生成两幅独立图像的有意义表示，然后在更高的层面组合到一起。**这有点类似与标准的图像匹配流程：首先从图像对的局部区域中提取出特征，然后将这些特征向量组合到一起。然而，在给定两幅图片的特征响应的情况下，网络如何获得响应呢？</p>
<p>​	为了帮助网络进行匹配，我们引入了一种称为“correlation layer”(关联层)的结构来在两幅特征图之间执行图片局部区域的乘法比较。包含了该关联层的‘FlowNetCorr’网络结构如图2下方所示。</p>
<p>在给定两幅多通道的特征图 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>f</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>f</mi><mn>2</mn></msub><mo>:</mo><msup><mi mathvariant="double-struck">R</mi><mn>2</mn></msup><mo>→</mo><msup><mi mathvariant="double-struck">R</mi><mi>C</mi></msup></mrow><annotation encoding="application/x-tex">f_1, f_2: \R^{2} \rightarrow \R^{C}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.07153em;">C</span></span></span></span></span></span></span></span></span></span></span></span> , 使用 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi><mo separator="true">,</mo><mi>h</mi><mo separator="true">,</mo><mi>c</mi></mrow><annotation encoding="application/x-tex">w, h, c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">h</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">c</span></span></span></span> 来代表他们的宽、高、通道数，我们的关联层让网络比较将 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>f</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">f_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的局部图像与 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>f</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">f_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的局部图像相比较。</p>
<p>​	现在，我们只考虑<strong>两个图像局部区域的单次比较</strong>。特征图1中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">x_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 处的局部图像与特征图2中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">x_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 处的局部图像的相关操作定义为：</p>
\begin{equation}c\left(\mathbf{x}_{1}, \mathbf{x}_{2}\right)=\sum_{\mathbf{o} \in[-k, k] \times[-k, k]}\left\langle\mathbf{f}_{1}\left(\mathbf{x}_{1}+\mathbf{o}\right), \mathbf{f}_{2}\left(\mathbf{x}_{2}+\mathbf{o}\right)\right\rangle \end{equation}

<p>​	对于一个方形的大小为K的小图片（<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>K</mi><mo>:</mo><mo>=</mo><mn>2</mn><mi>k</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">K:= 2k+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord">2</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>）(:= 为定义为的意思)，公式 (1) 等价于神经网络中的卷积中的一步操作，但与将数据与滤波器进行卷积不同，<strong>它是将数据与其它数据进行卷积。因此，这里没有可训练的权重。</strong></p>
<p>​	计算 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>c</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">c(x_1, x_2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">c</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 包含 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>c</mi><mo>⋅</mo><msup><mi>K</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">c\cdot K^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.44445em;vertical-align:0em;"></span><span class="mord mathdefault">c</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> 个乘法。比较所有小图片的组合涉及到 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">(</mo><mi>w</mi><mo>⋅</mo><mi>h</mi><mo stretchy="false">)</mo><mo>⋅</mo><mo stretchy="false">(</mo><mi>w</mi><mo>⋅</mo><mi>h</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>w</mi><mn>2</mn></msup><msup><mi>h</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">(w\cdot h)\cdot (w \cdot h)=w^2h^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">h</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">h</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> 个上述乘法，产生了很大的结果并且导致前向传播和反向传播都十分棘手。<strong>因此，为了降低计算量，我们限制了比较时候的最大位移，同时在两张特征图中引入跨步。</strong></p>
<p>​	给定最大位移为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">d</span></span></span></span> , 对于每个 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">x_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的位置我们只在大小为D（D定义为 2d+1） 的领域内计算相关关系 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>c</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">c(x_1, x_2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">c</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> ，通过限制 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">x_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 来实现。我们分别使用<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>s</mi><mn>1</mn></msub><mi mathvariant="normal">、</mi><msub><mi>s</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">s_1 、s_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">、</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的步长来全局 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">x_1,</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span></span></span></span> 在 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">x_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的邻域量化 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">x_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> .</p>
<p>​	理论上， 相关层产生的结果是四维的，**对于每个2D 图片的位置的组合，我们得到一个相关值，即分别包含裁剪后的图像像素值的两个向量的数量积。**实际中，我们使用通道来组织相对位移，这意味着我们得到的输出是 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi><mo>×</mo><mi>h</mi><mo>×</mo><msup><mi>D</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">w \times h \times D^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord mathdefault">h</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> .对于反向传播层，我们相应的实现了对相应的底团的导数。</p>
<p>​	<strong>细化。</strong>  CNNs 擅于通过交错的卷积和池化等操作来从图片中提取高维特征，即<strong>空间收缩特征映射</strong>。**池化是必要的，为了使得网络训练在计算上可行，更基础的是，能够从输入图像区域的中聚合信息。**然而，池化操作导致图像分辨率下降，为了实现密集的像素级的预测，我们需要一种方式来细化得到的粗糙池化表示。</p>
<p>​	我们使用的<strong>细化方法</strong>如图三所示。<strong>主要成分是“上采样”层，包括向上池化（unpooling, 拓展特征图，与池化操作相反）和一个卷积。<strong>这样的层之前已经有学者使用过。为了进行细化，我们对特征图使用上采样卷积，并且将其与</strong>“收缩”部分的网络中响应的特征图中的结果</strong>、和<strong>粗糙的预测光流上采样结果</strong>（如果有预测光流）相<strong>拼接</strong>。通过这种方式，我们既保留了来自粗糙特征图的高层信息也保留了来自低层特征图的详细局部信息。每一个步骤都将两次提高分辨率。我们重复上述操作四次，结果预测光流的分辨率依然小于输入四倍。</p>
<p>​	我们发现从该分辨率进一步细化，与使用计算量更小的<strong>双线性插值算法相比没有显著的提高效果</strong>。<strong>双线性插值算法的结果就是网络最终得到的预测结果。</strong></p>
<p>​	在另一种方案中，与使用双线性插值不同，我们使用来自论文《Large displacement optical flow: descriptor matching in variational motion estimation.》中<strong>无匹配项的变分法</strong>。我们使用4倍下采样分辨率图，然后使用该方案在 20 次迭代后将光流恢复至全分辨率。最终，我们在全分辨率图片上再执行五次迭代。我们另外计算了图片的边界，使用的方法来自论文《》，同时为了考虑检测到的边界我们使用<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi><mo>=</mo><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mo>−</mo><mi>λ</mi><mi>b</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><msup><mo stretchy="false">)</mo><mi>k</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\alpha = \exp(-\lambda b(x,y)^k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.099108em;vertical-align:-0.25em;"></span><span class="mop">exp</span><span class="mopen">(</span><span class="mord">−</span><span class="mord mathdefault">λ</span><span class="mord mathdefault">b</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>  替代了平滑因子，其中 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>b</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">b(x,y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">b</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span> 是指在对应尺度和像素间重新采样得到的薄边界的强度。这种上采样方法比简单的双线性插值算法计算开销更大，但是能够获得更加平滑和获得子像素级别平滑的光流场。在下文中，我们将使用这种变分方法得到的结果使用后缀“+v” 表示。图 4 中可以看到一个使用变分法得到的例子。</p>
<h3 id="training-data"><a class="markdownIt-Anchor" href="#training-data"></a> Training Data</h3>
<p>​	与传统方法不同，神经网络需要有数据真值的数据，不仅仅是为了优化几个参数，而是为了从零开始学会执行该任务。通常来说，获得这样的真实值是困难的，因为准确的像素级对应的显示世界场景是不容易确定的。在表1中给出了可用数据集的概述。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2020/png/211857/1583143864847-50f3cdd8-c84b-42de-96d2-76c4b96706be.png" alt="" /></p>
<h4 id="existing-datasets"><a class="markdownIt-Anchor" href="#existing-datasets"></a> Existing Datasets</h4>
<p>Middlebury 数据集只包含8对图片用于训练，其光流值是使用四种不同的方法生成的。<strong>运动位移很小</strong>，典型小于10像素。</p>
<p>​	KITTI 数据集更大一些（194 对训练图片）并且**包含大位移，但是只包含非常特殊的运动类型。**其地面真实值是通过使用摄像机和3D激光扫描仪同时对真实世界场景进行记录得到的。其假定场景是刚性的，并且运动来自移动的观察者。此外，远距离物体的运动，如天空，无法捕捉，导致了稀疏的光流值。</p>
<p>​	MPI Sintel 数据集从人造场景中获取真实值，并且十分关注现实的图片属性。提供了两种版本：<strong>最终版本包含了运动模糊和大气效应，如雾，而干净的版本则不包含这些影响。<strong>Sintel 数据集是可用的最大的数据集（各个版本都有 1041 对训练图片）并且为</strong>小位移和大位移都提供了地表真实值。</strong></p>
<h4 id="flying-chairs"><a class="markdownIt-Anchor" href="#flying-chairs"></a> Flying Chairs</h4>
<p>​	Sintel 数据集对于训练大型 CNNs来说还是太小了。为了提供足够的训练数据，我们创造了一个简单的合成数据集，我们将其称为“飞椅”，通过将仿射变换应用到从 Flicker 收集来的图片和一个公开的3D椅子模型得到。我们从 Flicker 检索了 964 张分辨率为1024x768 的图片，各个分类下的图片为：“city”（321），“landscape”（129），和“mountain” (514). 我们将其切割到四个象限，得到512x384 的图片作为背景。作为前景物体，我们将来自论文《Seeing 3d chairs: exemplar part-based 2d-3d alignment using a large dataset of cad models》的多张椅子的图片添加到背景图片中。从原始数据集中，我们移除了十分相似的椅子，得到809种椅子类型，每种椅子有 62 种不同视图。图5 展示了一个例子。</p>
<p>​	为了产生运动，我们**为背景和椅子随机采样仿射变换参数。椅子的变化和背景的变化是相关的，可以理解为相机和物体都进行了运动。**使用变换参数，我们对第二张图片、光流和闭塞区域进行了渲染。</p>
<p>​	<strong>每对图像的参数（数量、类型、尺寸和椅子的初始位置、变换参数）都是随机采样得到的。我们调整了这些参数的随机分布，使结果的位移直方图与Sintel 数据集中的相同。</strong>（细节可以从支撑材料中得知）。使用上述流程，我们生成了 22872 对图片和光流场（我们多次复用了背景图片）的数据集。注意这个大小是随意选取的，理论上可以更大。</p>
<h4 id="data-augmentation"><a class="markdownIt-Anchor" href="#data-augmentation"></a> Data Augmentation</h4>
<p>​	数据增强是一种广泛使用的用于改善神经网络泛化性能的方法。即使飞椅数据集十分大了，我们发现使用数据增强来避免过拟合仍然是十分重要的。我们在网络训练时使用在线的数据增强。我们使用的几何变换包括：平移、旋转和缩放，以及附加高斯随机噪声、改变亮度、对比度、伽马和颜色。为了比较快，这些操作都是在GPU上执行的。图 5 中给出了一些数据增强的例子。</p>
<p>​	因为我们不仅要<strong>增加图片的多样性，也要增加光流的多样性</strong>，我们对图片对使用了相同的强变换，但另外对图片对进行了较小的相对变换。我们对光流进行相应的调整，对光流从两侧应用单张图片的增强。</p>
<p>​	特别的，我们的x、y平移采样范围为图片宽度的 【-20%， 20%】,旋转角度范围为[-17, 17]，缩放尺度为【0.9， 2.0】，高斯噪声的 sigma 采样范围为 【0， 0.04】，对比度采样范围为 【-0.8， 0.4】，每张图片的乘色变化范围为【0.5,2】，gamma 数值范围为【0.7,1.5】，添加的亮度变化使用sigma为0.2 的高斯函数。</p>
<h3 id="experiments"><a class="markdownIt-Anchor" href="#experiments"></a> Experiments</h3>
<p>​	我们报告我们的网络在 Sintel、KITTI 和 Middlebury几个数据集, 同时包括我们合成的飞椅数据集上的结果。我们同时也试验了在 Sintel数据集上微调网络以及使用变分方法来细化预测的光流场。此外，相比于其他方法我们报告了网络的运行时间。</p>
<h4 id="network-and-trainging-details"><a class="markdownIt-Anchor" href="#network-and-trainging-details"></a> Network and Trainging Details</h4>
<p><img src="https://cdn.nlark.com/yuque/0/2020/png/211857/1583143741937-72fde948-76e2-4480-929c-38b7c7df071a.png" alt="" /></p>
<p>​	我们网络的确切结构如图2所示。总的来说，我们努力保持不同网络的结构一致性：他们都有9个卷积层，其中6个包含步长为2的最简单形式的池化层，每层后面都使用 ReLU 非线性函数激活。网络不包含全连接层，因此网络输入的图片可以是任意大小的。卷积核大小随着网络深度加深而减小：第一层使用 7x7, 后面两层使用 5x5, 从第四层开始使用 3x3 。特征图的数量随着层数加深而增加，大概是在每个步长为2的网络层后加倍。对于 FlowNetC 中的相关层，我们使用的参数是 k=0, d=20，s1=1, s2=2. 至于训练损失我们使用端点误差（EPE），这是光流估计的标准误差测量方法。它是预测光流与光流真实数值的欧式距离，对所有像素取平均值。</p>
<p>对于训练 CNNs, 我们使用修改过的 caffe 框架。我们使用 Adam 作为优化方法，因为在我们的任务中它比动量随机梯度下降收敛更快。我们固定Adam 的参数为： <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>β</mi><mn>1</mn></msub><mo>=</mo><mn>0.9</mn><mspace width="1em"/><msub><mi>β</mi><mn>2</mn></msub><mo>=</mo><mn>0.999</mn></mrow><annotation encoding="application/x-tex">\beta_1=0.9 \quad \beta_2=0.999</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span><span class="mspace" style="margin-right:1em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span><span class="mord">9</span><span class="mord">9</span></span></span></span> . 因为在某种意义上说，每个像素都是一个训练样本，因此我们使用很小的迷你批量大小为8. 我们从学习率为 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi><mo>=</mo><mn>1</mn><mi>e</mi><mo>−</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">\lambda =1e-4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">λ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord mathdefault">e</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">4</span></span></span></span> 开始，在300k 迭代后，每过 100k 循环便将其缩小一半。在 FlowNetS 上，使用 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi><mo>=</mo><mn>1</mn><mi>e</mi><mo>−</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">\lambda =1e-4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">λ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord mathdefault">e</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">4</span></span></span></span> 我们观察到了梯度爆炸。为了解决该问题，我们使用十分小的学习率开始  <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi><mo>=</mo><mn>1</mn><mi>e</mi><mo>−</mo><mn>6</mn></mrow><annotation encoding="application/x-tex">\lambda =1e-6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">λ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord mathdefault">e</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">6</span></span></span></span> ，在10k循环后慢慢的将其增加到  <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi><mo>=</mo><mn>1</mn><mi>e</mi><mo>−</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">\lambda =1e-4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">λ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord mathdefault">e</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">4</span></span></span></span>  ，然后遵循之前说的流程训练。</p>
<p>​	为了观察训练和微调过程中的过拟合，我们将飞椅数据集分割为 22232 训练和 640张测试例子，将 Sintel 数据集分为 908 用于训练以及 133 用于验证。</p>
<p>​	我们发现在测试时将图片放大有利于改善性能。尽管放大的大小取决于具体的数据集，我们为所有任务上的网络都固定了一次放大大小。对于 FlowNetS 我们没有放大，对于 FlowNetC 我们选择的缩放因子是 1.25.</p>
<p>​	<strong>Fine-tuning.</strong>  我们使用的数据集在<strong>物体类型和运动类型</strong>上都十分特殊。一种标准的解决方案是在目标数据集上微调模型。KITTI 数据集比较小并且只有稀疏的光流真值。因此，我们选择在 Sintel 训练集上微调模型。我们同时使用来自 Clean 和 Final 版本的 Sintel 数据集，使用十分小的学习率  <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi><mo>=</mo><mn>1</mn><mi>e</mi><mo>−</mo><mn>6</mn></mrow><annotation encoding="application/x-tex">\lambda =1e-6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">λ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord mathdefault">e</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">6</span></span></span></span>  在几千次迭代微调模型。为了发挥模型最好的性能，在使用验证集确定了最优的迭代次数后，我们使用同样迭代次数在整个训练集上微调模型。在表格中我们使用“+ft” 后缀来标识微调模型。</p>
<h4 id="results"><a class="markdownIt-Anchor" href="#results"></a> Results</h4>
<p><img src="https://cdn.nlark.com/yuque/0/2020/png/211857/1583143786048-fd181261-5480-4f64-ab12-db3f0263ee18.png" alt="" /></p>
<p>​	表格2展示了我们的网络和几种效果良好的算法在公共数据集(Sintel、KITTI， Middlebury)上的 endpoint error(EPE), 也包括在我们的飞椅数据集。另外我们也展示了不同算法在Sintel 数据集上的运行时间。</p>
<p>​	网络是在非现实的飞椅数据集上训练的在真实的光流数据集上也表现良好，击败了著名的 LDOF 算法。在Sintel 数据集上微调后，我们的网络在 Sintel 数据集上能够超越与之竞争的实时算法 EPPM ，同时在 KITTI 上能够快两倍。</p>
<p><strong>Sintel</strong>  从表2 我们可以看到, 在Sintel Clean 数据集上FlowNetC 网络比 FlowNetS 表现更好，但是在 Sintel Final 数据集上情况则相反。在这个困难的数据集上， FlowNetS+ft+v 甚至可以与 DeepFlow 相提并论。因为平均 endpoint error 通常偏向于过平滑的解，看到我们的方法的定量结果还是十分有趣的。图7展示了两种网络产生的原始预测光流数据（没有进行微调），将之与地表真值与EpicFlow 结果进行对比。该图展示了网络是如何产生在视觉上吸引人但是在endpoint error 上却更差。<strong>仔细观察后发现可能是因为网络产生非平滑的输出，特别是在大面积光滑的背景区域。<strong>这个问题我们可以使用</strong>变分方法细化</strong>来补偿。</p>
<p><strong>KITTI.</strong>  KITTI 数据集包含了较强的投影变换，这在网络在飞椅数据集上训练时遇到的情况十分不同。再一次，网络的原始输出仍然已经十分良好，额外的微调和变分调整让结果进一步变好。有趣的是，在 Sintel 数据集上的微调改善了网络在 KITTI 上的表现，可能是因为在Sintel 数据集上的图像和运动比飞椅数据集上的更加自然。<strong>FlowNetS 在这个数据集上的表现优于 FlowNetC.</strong></p>
<p><strong>Flying Chairs.</strong>  我们的网络在飞椅数据集上训练，因此网络被期待在该数据集上表现最好。当训练时，我们预留出一个包含 640 张图片的测试集。表 2 展示了在该测试集上多种算法的结果，图 6 中展示了一些例子。可以看到 FlowNetC 表现超过了 FlowNetS ，网络的表现超过了所有当前最佳算法。另一个有趣的发现是，这是唯一的变分方法细化没有提高网络性能，反而使得结果更差了。显然，<strong>网络已经可以做的比变分细化更好。这也暗示了当使用更加真实的数据集训练时，网络在其他数据集上甚至可能表现更好。</strong></p>
<p><strong>Timing.</strong>  在表 2 中， 我们展示不同算法每一帧需要的计算时间（按秒计算）。不幸的是，很多算法只提供了在单张 CPU 上的计算时间，我们的 FlowNet 使用的网络层只能在 GPU 上实现。网络的错误率低于当前最佳水平，但是在实时的算法中是最好的。在训练和测试时我们都使用的是 NVIDIA GTX Tian GPU.  DeepFlow 和 EpicFlow 的CPU 计算时间来自论文《Learning hierarchical features for scene labeling》，LDOF 算法的时间是在单张 2.66 GHz 核心的 CPU 计算的。</p>
<h4 id="analysis"><a class="markdownIt-Anchor" href="#analysis"></a> Analysis</h4>
<p><strong>Traing data.</strong>   为了验证我们是否从 使用飞椅数据集而不是 Sintel 数据集 这一决定中从中受益，我们使用 Sintel 数据集训练了一个网络，单独使用了一个验证集来控制性能。感谢积极的数据扩充，即使单独使用 Sintel 也能够很好的学习光流。 当在 Sintel 上测试的时候，在 Sintel 上专门训练的网络的 EPE 比在飞椅数据集训练然后在 Sintel 上微调的网络大约高一个像素。</p>
<p>​	飞椅数据集已经十分大了，所以数据增强还有必要吗？答案是需要，不进行数据增强在飞椅数据集上训练的网络在 Sintel 数据集上测试的结果是 EPE 大概增加了两个像素。</p>
<p><strong>Comparing the architectures</strong>  在表2中的结果已经可以让我们对我们测试过的两种架构的长处和弱点下一个结论。</p>
<p>​	首先，FlowNetS 比 FlowNetC 在 Sintel Final 数据集上泛化的更好。另一方面，FlowNetC 在飞椅数据集和 Sintel Clean 数据集上比FlowNetS 表现更好。注意飞椅数据集中不像 Sintel Final 中一样包含运动模糊或雾。这些结果暗示即使两个网络的参数数量实际上是相同的，FlowNetC 稍微有一点点对训练数据过拟合。这不意味着网络在记住了训练样本，但是它适应了在训练过程中的展现的数据。虽然在我们设置中这个可能是一个缺点，但是如果具有更好的训练数据，这可以成为一个优点。</p>
<p>​	第二，**FlowNetC 似乎在大位移方面有很多问题。**这可以从上面讨论的 KITTI 结果中看到，同时可以从在 Sintel Final 的详细性能表现中得知（没有在表中展示）。 FlowNetS+ft 达到了一个 s40+ error (有至少有40个像素的位移的像素上的 EPE)  为 43.3px，对于 FlowNetC+ft 这个数值为 48px。一个解释是关联层的最大位移限制导致了不能够预测到更大的运动。这个范围可以以牺牲计算效率来达到。</p>
<h3 id="conclusion"><a class="markdownIt-Anchor" href="#conclusion"></a> Conclusion</h3>
<p>​	得益于最近的卷积网络结构设计进展，**我们已经展现了直接从输入的一对图片中预测得到光流是可能的。**有趣的是，训练数据不需要是现实的。人造的飞椅数据集中只包含了合成的刚性物体的仿射运动就足以已以高准确率的性能来对自然场景中的光流进行预测。这证明了我们所展示的网络的泛化性能。在飞椅数据集的测试集上CNNs甚至能够超越当前最佳的如 DeepFlow 和 EpicFlow 的算法。当更多现实的训练数据可用时，网络的表现能够有多好让人期待！</p>
<h2 id="阅读心得"><a class="markdownIt-Anchor" href="#阅读心得"></a> 阅读心得</h2>
<p>网络主要可以分为： 传统的特征提取部分，光流所需的两张图片对应关系的提取部分（两张图片也是时序数据，如何使用时序的方法来处理？）</p>
<ul>
<li>如何提取两张图片之间的对应关系？训练一个小型的网络来专门提取对应关系？</li>
<li>金字塔结构提取，进行上采样和下采样，解决大小位移之间估计不准确的问题。</li>
<li>数据很重要，如何进一步增强数据处理过程</li>
</ul>
<h2 id="疑问"><a class="markdownIt-Anchor" href="#疑问"></a> 疑问</h2>
<ul>
<li>池化操作降低图像分辨率，是否真的必要？不使用池化操作直接实现端到端的编码解码如何？最大池化等操作使得图像信息丢失较多，是否有必要池化？</li>
<li>unpooling 是什么？</li>
<li>EPE 函数能否进行改进？像 Focal Loss?</li>
<li>为什么放大图片输入网络性能能更好，增加了信息的稀疏性?</li>
<li>图像的深度信息是什么？如何获得？（cvpr2009）</li>
</ul>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">yz-liu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://yzfly.github.io/2019/11/16/flownet/">https://yzfly.github.io/2019/11/16/flownet/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://yzfly.github.io">yzliu的小窝</a>！</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/deeplearning-Optical-Flow/">deeplearning Optical-Flow</a></div><div class="addthis_inline_share_toolbox pull-right"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5e5d0d0491330592" async></script><nav id="pagination"><div class="next-post pull-right"><a href="/2018/07/16/win%E5%92%8Clinux%E5%A4%9A%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE/"><span>linux 折腾记</span><i class="fa fa-chevron-right"></i></a></div></nav><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: 'b26e51824c79f2513f6f',
  clientSecret: '906f458a4fb9c1c3fedce4c82e605874616c9eda',
  repo: 'blog_comments',
  owner: 'yzfly',
  admin: 'yzfly',
  id: md5(decodeURI(location.pathname)),
  language: 'zh-CN'
})
gitalk.render('gitalk-container')</script></div></div><footer class="footer-bg" style="background-image: url(https://cdn.nlark.com/yuque/0/2020/png/211857/1583144212593-c7c016a1-24c0-47cc-bac7-4252aa4fb2f4.png)"><div class="layout" id="footer"><div class="copyright">&copy;2017 - 2020 By yz-liu</div><div class="framework-info"><span>驱动 - </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.7.0"></script><script src="/js/fancybox.js?version=1.7.0"></script><script src="/js/sidebar.js?version=1.7.0"></script><script src="/js/copy.js?version=1.7.0"></script><script src="/js/fireworks.js?version=1.7.0"></script><script src="/js/transition.js?version=1.7.0"></script><script src="/js/scroll.js?version=1.7.0"></script><script src="/js/head.js?version=1.7.0"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script src="/js/katex.js"></script><script src="/js/search/local-search.js"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>